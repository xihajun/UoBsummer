{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to generate adjacency matrices of our scripts in the juliet dataset to be used as input for our neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import networkx as nx\n",
    "from preprocess_code import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/buffer_overflow_data.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[500:599]\n",
    "# data = data.iloc[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_edge_list1(testcase, **kwargs):\n",
    "    \"\"\"\n",
    "    Takes in a list of files/datapoints from juliet.csv.zip \n",
    "    or (as loaded with pandas) matching one particular testcase, \n",
    "    and returns an edge list of its graph representation.\n",
    "    \"\"\"\n",
    "    parse_list = [\n",
    "        (datapoint.filename, datapoint.code)\n",
    "        for datapoint in testcase.itertuples()\n",
    "    ]\n",
    "\n",
    "    primary = find_primary_source_file(testcase)\n",
    "\n",
    "    # Parse the source code with clang, and get out an ast:\n",
    "    index = clang.cindex.Index.create()\n",
    "    translation_unit = index.parse(\n",
    "        path=primary.filename,\n",
    "        unsaved_files=parse_list,\n",
    "    )\n",
    "    ast_root = translation_unit.cursor\n",
    "\n",
    "    # Memoise/concretise the ast so that we can consistently\n",
    "    # modify it, then number each node in the tree uniquely.\n",
    "    concretise_ast(ast_root)\n",
    "    number_ast_nodes(ast_root)\n",
    "\n",
    "    # Next, construct an edge list for the graph2vec input:\n",
    "    edgelist = generate_edgelist(ast_root)\n",
    "    \n",
    "    edgelist_representation = {\n",
    "        \"edges\": edgelist,\n",
    "    }\n",
    "\n",
    "    # Explicitly delete clang objects\n",
    "    del translation_unit\n",
    "    del ast_root\n",
    "    del index\n",
    "\n",
    "    return json.dumps(edgelist_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_edge_list1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0b54c0c74acc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m graphs = data.groupby(['testcase_ID']).apply(\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mgenerate_edge_list1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'columns'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mmeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'generate_edge_list'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'unicode'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_edge_list1' is not defined"
     ]
    }
   ],
   "source": [
    "# dask_data = dd.from_pandas(data, npartitions=20)\n",
    "\n",
    "# generate the graphs for all the testcases in the dataset \n",
    "\n",
    "graphs = data.groupby(['testcase_ID']).apply(\n",
    "        generate_edge_list1,\n",
    "        axis='columns',\n",
    "        meta=('generate_edge_list', 'unicode'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_adj_matrix1(testcase):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes in a list of files/datapoints from buffer_overflow_data.csv.gz \n",
    "    matching one particular testcase, and generates an adjacency matrix \n",
    "    from the edgelist created.\n",
    "    \"\"\"\n",
    "    \n",
    "    # extracting the list of edges \n",
    "\n",
    "    x = testcase.split('edges\": ')\n",
    "    x = x[1].split('}')\n",
    "    x = ast.literal_eval(x[0])\n",
    "    \n",
    "#     return x\n",
    "\n",
    "    # generating the matrix\n",
    "    \n",
    "    G = nx.Graph()\n",
    "\n",
    "    G.add_edges_from(x)\n",
    "\n",
    "    A = nx.adjacency_matrix(G)\n",
    "\n",
    "    B = A.todense()\n",
    "\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe containing the testcase ID and its adjacency matrix \n",
    "adjacency_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_df['testcase_ID'] = data.testcase_ID.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel dies when there are more than 200 datapoints\n",
    "\n",
    "# adj_matrices = graphs.apply(gen_adj_matrix1, meta = ('generate_adj_matrices', 'O'))\n",
    "adj_matrices = graphs.apply(gen_adj_matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj_matrices = pd.DataFrame(adj_matrices)\n",
    "adj_matrices = adj_matrices.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: in a DASK framework reset_index is not a recognized function like pandas, fix this bug\n",
    "\n",
    "# adj_matrices = adj_matrices.compute()\n",
    "adj_matrices = adj_matrices.reset_index(level='testcase_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adjacency_df['adj_matrix'] = adj_matrices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_df = adjacency_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_df.to_csv(\"../data/adj_df.csv.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concretise_ast(node):\n",
    "    \"\"\"\n",
    "    Everytime you run .get_children() on a clang ast node, it\n",
    "    gives you new objects. So if you want to modify those objects\n",
    "    they will lose their changes everytime you walk the tree again.\n",
    "    To avoid this problem, concretise_ast walks the tree once,\n",
    "    saving the resulting list from .get_children() into a a concrete\n",
    "    list inside the .children.\n",
    "    You can then use .children to consistently walk over tree, and\n",
    "    it will give you the same objects each time.\n",
    "    \"\"\"\n",
    "    node.children = list(node.get_children())\n",
    "\n",
    "    for child in node.children:\n",
    "        counter = concretise_ast(child)\n",
    "\n",
    "def number_ast_nodes(node, counter=1):\n",
    "    \"\"\"\n",
    "    Given a concretised clang ast, assign each node with a unique\n",
    "    numerical identifier. This will be accessible via the .identifier\n",
    "    attribute of each node.\n",
    "    \"\"\"\n",
    "    node.identifier = counter\n",
    "    counter += 1\n",
    "\n",
    "    node.children = list(node.get_children())\n",
    "    for child in node.children:\n",
    "        counter = number_ast_nodes(child, counter)\n",
    "\n",
    "    return counter\n",
    "\n",
    "\n",
    "def generate_ast_roots(testcase, **kwargs):\n",
    "    \"\"\"\n",
    "    Takes in a list of files/datapoints from juliet.csv.zip (as loaded with pandas) matching one particular\n",
    "    testcase, and preprocesses it ready for the feature matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    parse_list = [\n",
    "        (datapoint.filename, datapoint.code)\n",
    "        for datapoint in testcase.itertuples()\n",
    "    ]\n",
    "\n",
    "    primary = find_primary_source_file(testcase)\n",
    "\n",
    "    # Parse the source code with clang, and get out an ast:\n",
    "    index = clang.cindex.Index.create()\n",
    "    translation_unit = index.parse(\n",
    "        path=primary.filename,\n",
    "        unsaved_files=parse_list,\n",
    "    )\n",
    "    ast_root = translation_unit.cursor\n",
    "    \n",
    "    concretise_ast(ast_root)\n",
    "    number_ast_nodes(ast_root)\n",
    "    \n",
    "    return ast_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast_roots = data.groupby(['testcase_ID']).apply(generate_ast_roots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__ctypes_from_outparam__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_b_base_',\n",
       " '_b_needsfree_',\n",
       " '_displayname',\n",
       " '_fields_',\n",
       " '_kind_id',\n",
       " '_objects',\n",
       " '_tu',\n",
       " 'access_specifier',\n",
       " 'availability',\n",
       " 'brief_comment',\n",
       " 'canonical',\n",
       " 'children',\n",
       " 'data',\n",
       " 'displayname',\n",
       " 'enum_type',\n",
       " 'enum_value',\n",
       " 'exception_specification_kind',\n",
       " 'extent',\n",
       " 'from_cursor_result',\n",
       " 'from_location',\n",
       " 'from_result',\n",
       " 'get_arguments',\n",
       " 'get_bitfield_width',\n",
       " 'get_children',\n",
       " 'get_definition',\n",
       " 'get_field_offsetof',\n",
       " 'get_included_file',\n",
       " 'get_num_template_arguments',\n",
       " 'get_template_argument_kind',\n",
       " 'get_template_argument_type',\n",
       " 'get_template_argument_unsigned_value',\n",
       " 'get_template_argument_value',\n",
       " 'get_tokens',\n",
       " 'get_usr',\n",
       " 'hash',\n",
       " 'identifier',\n",
       " 'is_abstract_record',\n",
       " 'is_anonymous',\n",
       " 'is_bitfield',\n",
       " 'is_const_method',\n",
       " 'is_converting_constructor',\n",
       " 'is_copy_constructor',\n",
       " 'is_default_constructor',\n",
       " 'is_default_method',\n",
       " 'is_definition',\n",
       " 'is_move_constructor',\n",
       " 'is_mutable_field',\n",
       " 'is_pure_virtual_method',\n",
       " 'is_scoped_enum',\n",
       " 'is_static_method',\n",
       " 'is_virtual_method',\n",
       " 'kind',\n",
       " 'lexical_parent',\n",
       " 'linkage',\n",
       " 'location',\n",
       " 'mangled_name',\n",
       " 'objc_type_encoding',\n",
       " 'raw_comment',\n",
       " 'referenced',\n",
       " 'result_type',\n",
       " 'semantic_parent',\n",
       " 'spelling',\n",
       " 'storage_class',\n",
       " 'tls_kind',\n",
       " 'translation_unit',\n",
       " 'type',\n",
       " 'underlying_typedef_type',\n",
       " 'walk_preorder',\n",
       " 'xdata']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example_node = ast_roots.iloc[0].children[19]\n",
    "# dir(example_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the columns for the feature matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_colnames(ast_root):\n",
    "    \"\"\"\n",
    "    Given a concretised & numbered clang ast, returns a set of node kinds to be used as columns in feature matrix\n",
    "    \"\"\"\n",
    "    features =  set()\n",
    "\n",
    "\n",
    "    def walk_tree_and_set_features(node):\n",
    "        out_degree = len(node.children)\n",
    "        in_degree = 1\n",
    "        degree = out_degree + in_degree\n",
    "        \n",
    "        features.add(str(node.kind))\n",
    "\n",
    "#         features[node.identifier] = [str(node.kind)]\n",
    "\n",
    "        for child in node.children:\n",
    "            walk_tree_and_set_features(child)\n",
    "\n",
    "    walk_tree_and_set_features(ast_root)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def generate_spelling(ast_root):\n",
    "    \"\"\"\n",
    "    Given a concretised & numbered clang ast, returns a set of node spellings to be used later\n",
    "    in constructing the columns in feature matrix\n",
    "    \"\"\"\n",
    "    spelling =  set()\n",
    "\n",
    "\n",
    "    def walk_tree_and_set_features(node):\n",
    "        out_degree = len(node.children)\n",
    "        in_degree = 1\n",
    "        degree = out_degree + in_degree\n",
    "        \n",
    "        spelling.add(node.spelling)\n",
    "\n",
    "        for child in node.children:\n",
    "            walk_tree_and_set_features(child)\n",
    "\n",
    "    walk_tree_and_set_features(ast_root)\n",
    "\n",
    "    return spelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating unique set of node kinds and node spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ast_roots.apply(generate_colnames)\n",
    "spelling = ast_roots.apply(generate_spelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obtaining final boolean column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_colnames = set()\n",
    "final_colnames.update(['WriteToPointer', 'SizeOf', 'Alloc'])\n",
    "for i in range(len(feature_sets)):\n",
    "    final_colnames.update(feature_sets.iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set of all node spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_spelling = set()\n",
    "for i in range(len(spelling)):\n",
    "    final_spelling.update(spelling.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_colnames = pd.Series(list(final_colnames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually pick out important node spellings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "alloc_list = ['__builtin_alloca', \n",
    "              '__alloc', \n",
    "              'malloc', \n",
    "              'valloc', \n",
    "              '__alloc_on_copy', \n",
    "              '__alloc_on_move', \n",
    "              'calloc', \n",
    "              'realloc', \n",
    "              'alloca',\n",
    "              'ALLOCA'\n",
    "             ]\n",
    "\n",
    "sizeOf_list = ['std::aligned_storage<sizeof(_Tp), __alignof(_Tp)>'\n",
    "              ]\n",
    "\n",
    "writeToPointer_list = ['__builtin_memmove', \n",
    "                       '__builtin_memcpy', \n",
    "                       'wmempcpy', \n",
    "                       'wmemmove'\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [feature for feature in final_spelling if 'Alloc' in feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.get_dummies(final_colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the feature matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features_pdf(ast_root):\n",
    "    \"\"\"\n",
    "    Given a concretised & numbered clang ast, return a dictionary of\n",
    "    features in the form:\n",
    "        {\n",
    "            <node_id>: [<type>, <description>],\n",
    "            ...\n",
    "        }\n",
    "        \n",
    "    To extract whether a node has the properties of WriteToPointer, SizeOf or Alloc\n",
    "    \"\"\"\n",
    "    index = []\n",
    "    kind = {}\n",
    "    spelling = {}\n",
    "\n",
    "    def walk_tree_and_set_properties(node):\n",
    "        out_degree = len(node.children)\n",
    "        in_degree = 1\n",
    "        degree = out_degree + in_degree\n",
    "        \n",
    "        index.append(node.identifier)\n",
    "        \n",
    "        kind[node.identifier] = node.kind\n",
    "        spelling[node.identifier] = node.spelling\n",
    "        \n",
    "        if str(node.spelling) in writeToPointer_list:\n",
    "            spelling[node.identifier] = 'writeToPointer'\n",
    "        \n",
    "        elif str(node.spelling) in sizeOf_list:\n",
    "            spelling[node.identifier] = 'sizeOf'\n",
    "            \n",
    "        elif str(node.spelling) in alloc_list:\n",
    "            spelling[node.identifier] = 'alloca'\n",
    "        \n",
    "        else:\n",
    "            spelling[node.identifier] = ''\n",
    "        \n",
    "\n",
    "        for child in node.children:\n",
    "            walk_tree_and_set_properties(child)\n",
    "\n",
    "    walk_tree_and_set_properties(ast_root)\n",
    "    \n",
    "#     return spelling\n",
    "    \n",
    "    d = {'identifier': index, 'kind': list(kind.values()), 'spelling': list(spelling.values())}\n",
    "        \n",
    "    final_df = pd.DataFrame(data = d)\n",
    "    final_df = final_df.set_index('identifier')\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>spelling</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CursorKind.TRANSLATION_UNIT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CursorKind.FUNCTION_DECL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CursorKind.COMPOUND_STMT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CursorKind.DECL_STMT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CursorKind.VAR_DECL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CursorKind.BINARY_OPERATOR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CursorKind.DECL_REF_EXPR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CursorKind.CSTYLE_CAST_EXPR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CursorKind.CALL_EXPR</td>\n",
       "      <td>alloca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CursorKind.UNEXPOSED_EXPR</td>\n",
       "      <td>alloca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CursorKind.DECL_REF_EXPR</td>\n",
       "      <td>alloca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CursorKind.BINARY_OPERATOR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CursorKind.UNEXPOSED_EXPR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CursorKind.INTEGER_LITERAL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CursorKind.CXX_UNARY_EXPR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CursorKind.COMPOUND_STMT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CursorKind.DECL_STMT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CursorKind.VAR_DECL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CursorKind.INTEGER_LITERAL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CursorKind.INIT_LIST_EXPR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CursorKind.INTEGER_LITERAL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CursorKind.CALL_EXPR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CursorKind.UNEXPOSED_EXPR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CursorKind.DECL_REF_EXPR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CursorKind.UNEXPOSED_EXPR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CursorKind.ARRAY_SUBSCRIPT_EXPR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CursorKind.UNEXPOSED_EXPR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CursorKind.DECL_REF_EXPR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CursorKind.INTEGER_LITERAL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>CursorKind.FUNCTION_DECL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CursorKind.COMPOUND_STMT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CursorKind.CALL_EXPR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>CursorKind.UNEXPOSED_EXPR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CursorKind.DECL_REF_EXPR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       kind spelling\n",
       "identifier                                          \n",
       "1               CursorKind.TRANSLATION_UNIT         \n",
       "2                  CursorKind.FUNCTION_DECL         \n",
       "3                  CursorKind.COMPOUND_STMT         \n",
       "4                      CursorKind.DECL_STMT         \n",
       "5                       CursorKind.VAR_DECL         \n",
       "6                CursorKind.BINARY_OPERATOR         \n",
       "7                  CursorKind.DECL_REF_EXPR         \n",
       "8               CursorKind.CSTYLE_CAST_EXPR         \n",
       "9                      CursorKind.CALL_EXPR   alloca\n",
       "10                CursorKind.UNEXPOSED_EXPR   alloca\n",
       "11                 CursorKind.DECL_REF_EXPR   alloca\n",
       "12               CursorKind.BINARY_OPERATOR         \n",
       "13                CursorKind.UNEXPOSED_EXPR         \n",
       "14               CursorKind.INTEGER_LITERAL         \n",
       "15                CursorKind.CXX_UNARY_EXPR         \n",
       "16                 CursorKind.COMPOUND_STMT         \n",
       "17                     CursorKind.DECL_STMT         \n",
       "18                      CursorKind.VAR_DECL         \n",
       "19               CursorKind.INTEGER_LITERAL         \n",
       "20                CursorKind.INIT_LIST_EXPR         \n",
       "21               CursorKind.INTEGER_LITERAL         \n",
       "22                     CursorKind.CALL_EXPR         \n",
       "23                CursorKind.UNEXPOSED_EXPR         \n",
       "24                 CursorKind.DECL_REF_EXPR         \n",
       "25                CursorKind.UNEXPOSED_EXPR         \n",
       "26          CursorKind.ARRAY_SUBSCRIPT_EXPR         \n",
       "27                CursorKind.UNEXPOSED_EXPR         \n",
       "28                 CursorKind.DECL_REF_EXPR         \n",
       "29               CursorKind.INTEGER_LITERAL         \n",
       "30                 CursorKind.FUNCTION_DECL         \n",
       "31                 CursorKind.COMPOUND_STMT         \n",
       "32                     CursorKind.CALL_EXPR         \n",
       "33                CursorKind.UNEXPOSED_EXPR         \n",
       "34                 CursorKind.DECL_REF_EXPR         "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eg = generate_features_pdf(ast_roots.iloc[4])\n",
    "generate_features_pdf(ast_roots.iloc[4])\n",
    "\n",
    "# '__alloc' in eg.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: figure out how to get this dataframe for all the testcases IDS stored in one place then apply this to the rest of the data to be converted into matrix format"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
